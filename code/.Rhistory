<<<<<<< HEAD
cities <- str_replace(cities, "\\[\\d+\\]", "") # remove the footnote symbols
cities[1:10]
cities
# extract variables
year <- str_extract(cities, "\\d{4}")
city <- str_extract(cities, "[[:alpha:] ]+") %>% str_trim
country <- str_extract(cities, "[[:alpha:] ]+$") %>% str_trim
year[1:10]
city[1:10]
country[1:10]
# make data frame
cities_df <- data.frame(year, city, country)
cities_df
head(cities_df)
library(nominatim)
# geocode observations with nominatim package
devtools::install_github("hrbrmstr/nominatim") # not on CRAN, so install from GitHub
library(nominatim)
cities_to_geocode <- paste0(cities_df$city, ", ", cities_df$country)
cities_to_geocode
# get free API key at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzert/rkeys.RDa") # load key from local file; you have to create your own file or paste your key into an object named 'openstreetmap'
# get free API key at browseURL("https://developer.mapquest.com/")
load("/Users/simonmunzert/rkeys.RDa") # load key from local file; you have to create your own file or paste your key into an object named 'openstreetmap'
lats_longs <- osm_geocode(cities_to_geocode, key = openstreetmap)
lats_longs[c("lat", "lon")]
# map observations
map_world <- borders("world", colour = "gray50", fill = "white")
ggplot() + map_world + geom_point(aes(x = lats_longs$lon, y = lats_longs$lat), color = "red", size = 1) + theme_void()
save(lat_longs, file = "cities_lat_longs.RData")
save(lats_longs, file = "cities_lat_longs.RData")
library(stringr)
## string basics -----------------
# to create strings, both single and double quotes work
string1 <- 'This is a string'
string2 <- 'If I want to include a "quote" inside a string, I use single quotes'
# to include a literal single or double quote in a string you can use \ to escape it:
double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'"
# many special characters around, see
?"'"
# example
=======
} else {
load("geocodes_breweries.RData")
}
head(pos)
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
install.packages("rnaturalearthdata")
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
install.packages("rgeos")
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
germany <- worldmap[worldmap$name == 'Germany',]
ggplot() + geom_sf(data = germany) + theme_bw() + geom_point(aes(lon,lat), data = pos, size = .5, color = "red")
View(mtcars)
# enter your R code here
sum(1, 2)
sum(1, 2)
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
library(tidyverse)
library(rvest)
>>>>>>> 46f5126cd0b1f469af3c6c745d3505a0798f6d90
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
phone
# diagnosis
str_extract("+test" , "\\+.+")
# diagnosis
str_extract("+test" , "\\+.+")
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
# solution
str_extract("+test" , "(?<=\\+).+")
str_extract_all("Hello, my name is Simon" , "[[a-z]., ]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^., ]") # equivalent
## load packages
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
## step 1: fetch list of cities with breweries
url <- "http://www.biermap24.de/brauereiliste.php"
content <- read_html(url)
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
cities
cities <- str_trim(cities)
length(cities)
length(unique(cities))
sort(table(cities))
unique_cities <- unique(cities)
coords_df <- data.frame(city = NA, lon = NA, lat = NA, stringsAsFactors = FALSE)
if (!file.exists("coords_breweries.RData")){
for (i in 1:length(unique_cities)) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon <- as.numeric(coords$lon)
coords_df$lat <- as.numeric(coords$lat)
}else{
coords_df$lon <- NA
coords_df$lat <- NA
}
}
save(coords_df, file="coords_breweries.RData")
} else {
load("coords_breweries.RData")
}
## step 2: geocode cities
# get free key for mapquest API at browseURL("https://developer.mapquest.com/")
load("/Users/simonmunzert/rkeys.RDa") # import API key (or paste it here in openstreetmap object)
coords_df <- data.frame(city = NA, lon = NA, lat = NA, stringsAsFactors = FALSE)
if (!file.exists("coords_breweries.RData")){
for (i in 1:length(unique_cities)) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon <- as.numeric(coords$lon)
coords_df$lat <- as.numeric(coords$lat)
}else{
coords_df$lon <- NA
coords_df$lat <- NA
}
}
save(coords_df, file="coords_breweries.RData")
} else {
load("coords_breweries.RData")
}
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
for (i in 1:10) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city[i] <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon[i] <- as.numeric(coords$lon)
coords_df$lat[i] <- as.numeric(coords$lat)
}else{
coords_df$lon <- NA
coords_df$lat <- NA
}
}
coords_df
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
if (!file.exists("coords_breweries.RData")){
for (i in 1:n_cities) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city[i] <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon[i] <- as.numeric(coords$lon)
coords_df$lat[i] <- as.numeric(coords$lat)
}else{
coords_df$lon <- NA
coords_df$lat <- NA
}
}
save(coords_df, file="coords_breweries.RData")
} else {
load("coords_breweries.RData")
}
save(coords_df, file="coords_breweries.RData")
View(coords_df)
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords
coords_df$lat
coords$lat
nrow(coords)
coords
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
for (i in 1:n_cities) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city[i] <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon[i] <- as.numeric(coords$lon)
coords_df$lat[i] <- as.numeric(coords$lat)
}else{
coords_df$lon[i] <- NA
coords_df$lat[i] <- NA
}
}
save(coords_df, file="coords_breweries.RData")
View(coords_df)
head(coords_df)
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
## step 3: plot breweries of Germany
pos <- filter(coords_df, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
germany <- worldmap[worldmap$name == 'Germany',]
ggplot() + geom_sf(data = germany) + theme_bw() + geom_point(aes(lon,lat), data = pos, size = .5, color = "red")
# load RSelenium
library(tidyverse)
library(rvest)
library(RSelenium)
# initiate Selenium driver
rD <- rsDriver(browser = "chrome")
remDr <- rD[["client"]]
# start browser, navigate to page
url <- "https://www.imdb.com/search/title"
remDr$navigate(url)
# enter keyword in title field
xpath <- '//*[@id="main"]/div[1]/div[2]/input'
titleElem <- remDr$findElement(using = 'xpath', value = xpath)
titleElem$sendKeysToElement(list("data")) # enter key word
# close connection
remDr$closeServer()
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
browseURL("http://www.biermap24.de/brauereiliste.php")
## step 1: fetch list of cities with breweries
url <- "http://www.biermap24.de/brauereiliste.php"
content <- read_html(url)
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
cities
cities <- str_trim(cities)
length(cities)
length(unique(cities))
sort(table(cities))
## step 1: fetch list of cities with breweries
url <- "http://www.biermap24.de/brauereiliste.php"
content <- read_html(url)
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
cities
cities <- str_trim(cities)
length(cities)
length(unique(cities))
sort(table(cities))
## step 2: geocode cities
# get free key for mapquest API at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzrt/rkeys.RDa") # import API key (or paste it here in openstreetmap object)
## step 2: geocode cities
# get free key for mapquest API at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzert/rkeys.RDa") # import API key (or paste it here in openstreetmap object)
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
n_cities <- length(unique_cities)
unique_cities <- unique(cities)
n_cities <- length(unique_cities)
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
if (!file.exists("coords_breweries.RData")){
for (i in 1:n_cities) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city[i] <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon[i] <- as.numeric(coords$lon)
coords_df$lat[i] <- as.numeric(coords$lat)
}else{
coords_df$lon[i] <- NA
coords_df$lat[i] <- NA
}
}
save(coords_df, file="coords_breweries.RData")
} else {
load("coords_breweries.RData")
}
head(coords_df)
## step 3: plot breweries of Germany
pos <- filter(coords_df, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
install.packages("rnaturalearthdata")
## step 3: plot breweries of Germany
pos <- filter(coords_df, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
germany <- worldmap[worldmap$name == 'Germany',]
ggplot() + geom_sf(data = germany) + theme_bw() + geom_point(aes(lon,lat), data = pos, size = .5, color = "red")
url <- "https://en.wikipedia.org/wiki/List_of_female_scientists_in_the_20th_century"
browseURL(url)
# load packages
library(tidyverse)
library(rvest)
# parse page
url <- "https://en.wikipedia.org/wiki/List_of_state_leaders_in_2020"
url_parsed <- read_html(url)
# extract country nodes
country_nodes <- html_nodes(url_parsed, xpath = "//li[./child::b]")
country_text <- html_nodes(country_nodes, xpath = "./*[1]//a[1]")%>% html_text() # does not provide full list, because not all countries are in anchor tags
country_text <- html_nodes(country_nodes, xpath = "./*[1]")%>% html_text() %>% str_trim
country_text
# inspect structure of first country node
xml_structure(country_nodes[[1]])
# extract text for first two leaders
leader_1_text <- sapply(country_nodes, function(x) {html_nodes(x, xpath = "./ul/li[1]") %>% html_text()})
leader_1_text[lengths(leader_1_text) == 0] <- ""
leader_2_text <- sapply(country_nodes, function(x) {html_nodes(x, xpath = "./ul/li[2]") %>% html_text()})
leader_2_text[lengths(leader_2_text) == 0] <- ""
# extract links for first two leaders
leader_1_link <- sapply(country_nodes, function(x) {html_nodes(x, xpath = "./ul/li[1]/a[1]") %>% html_attr("href")})
leader_1_link[lengths(leader_1_link) == 0] <- ""
leader_2_link <- sapply(country_nodes, function(x) {html_nodes(x, xpath = "./ul/li[2]/a[1]") %>% html_attr("href")})
leader_2_link[lengths(leader_2_link) == 0] <- ""
# compile data frame
dat <- data.frame(country = country_text,
leader_1 = unlist(leader_1_text),
leader_1_link = unlist(leader_1_link),
leader_2 = unlist(leader_2_text),
leader_2_link = unlist(leader_2_link),
stringsAsFactors = FALSE)
View(dat)
# load RSelenium
library(tidyverse)
library(rvest)
library(RSelenium)
# initiate Selenium driver
rD <- rsDriver(browser = "chrome")
# close connection
remDr$closeServer()
# initiate Selenium driver
rD <- rsDriver(browser = "chrome")
remDr <- rD[["client"]]
# start browser, navigate to page
url <- "https://www.imdb.com/search/title"
remDr$navigate(url)
# load RSelenium
library(tidyverse)
library(rvest)
library(RSelenium)
# initiate Selenium driver
rD <- rsDriver(browser = "chrome")
remDr <- rD[["client"]]
# start browser, navigate to page
url <- "https://www.imdb.com/search/title"
remDr$navigate(url)
# enter keyword in title field
xpath <- '//*[@id="main"]/div[1]/div[2]/input'
titleElem <- remDr$findElement(using = 'xpath', value = xpath)
titleElem$sendKeysToElement(list("data")) # enter key word
# select requested title data
xpath <- '//*[@id="main"]/div[8]/div[2]/select/option[7]' # plot
titledatElem1 <- remDr$findElement(using = 'xpath', value = xpath)
titledatElem1$clickElement() # click on list element
xpath <- '//*[@id="main"]/div[8]/div[2]/select/option[10]' # technical info
titledatElem2 <- remDr$findElement(using = 'xpath', value = xpath)
titledatElem2$clickElement() # click on list element
# scroll to end of page (just for fun)
webElem <- remDr$findElement("css", "body")
webElem$sendKeysToElement(list(key = "end"))
# click on search button
xpath <- '//*[@id="main"]/p[3]/button'
searchElem <- remDr$findElement(using = 'xpath', value = xpath)
searchElem$clickElement() # click on button
# store index page
output <- remDr$getPageSource(header = TRUE)
write(output[[1]], file = "data/imdb-data-movies.html")
# close connection
remDr$closeServer()
# parse html
content <- read_html("data/imdb-data-movies.html")
titles <- html_nodes(content, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "lister-item-header", " " ))]//a') %>% html_text
head(titles)
write(output[[1]], file = "imdb-data-movies.html")
dir.create("data")
write(output[[1]], file = "data/imdb-data-movies.html")
# close connection
remDr$closeServer()
# parse html
content <- read_html("data/imdb-data-movies.html")
titles <- html_nodes(content, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "lister-item-header", " " ))]//a') %>% html_text
head(titles)
I tried different things with importing them with pdf_text or different OCR packages but I quite never found efficient ways to then import and clean data in bulk.
Thanks!
<br>
library(tidyverse)
library(rvest)
library(pdftools)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
## step 1: inspect page
url <- "http://ajps.org/list-of-reviewers/"
## step 3: import pdf
rev_raw <- pdftools::pdf_text("ajps-reviewers/reviewers2015.pdf")
class(rev_raw)
rev_raw[1]
## step 4: tidy data
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
surname <- str_extract(rev_all, "[[:alpha:]-]+")
prename <- str_extract(rev_all, " [.[:alpha:]]+")
rev_df <- data.frame(raw = rev_all, surname = surname, prename = prename, stringsAsFactors = F)
rev_df$institution <- NA
for(i in 1:nrow(rev_df)) {
rev_df$institution[i] <- rev_df$raw[i] %>% str_replace(rev_df$surname[i], "") %>% str_replace(rev_df$prename[i], "") %>% str_trim()
}
rev_df <- rev_df[-c(1,2),]
rev_df <- rev_df[!is.na(rev_df$surname),]
head(rev_df)
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
browseURL("http://www.biermap24.de/brauereiliste.php")
## step 1: fetch list of cities with breweries
url <- "http://www.biermap24.de/brauereiliste.php"
content <- read_html(url)
class(content)
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
head(cities)
cities <- str_trim(cities)
length(cities)
length(unique(cities))
sort(table(cities))
unique_cities <- unique(cities)
## step 2: geocode cities
# get free key for mapquest API at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzert/rkeys.RDa") # import API key (or paste it here in openstreetmap object)
nominatim::osm_search("Berlin")
nominatim::osm_search("Berlin", key = openstreetmap)
dir()
n_cities <- length(unique_cities)
coords_df <- data.frame(city = rep(NA, n_cities), lon = rep(NA, n_cities), lat = rep(NA, n_cities), stringsAsFactors = FALSE)
if (!file.exists("coords_breweries.RData")){
for (i in 1:n_cities) {
coords <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap))
coords_df$city[i] <- unique_cities[i]
if(nrow(coords) > 0) {
coords_df$lon[i] <- as.numeric(coords$lon)
coords_df$lat[i] <- as.numeric(coords$lat)
}else{
coords_df$lon[i] <- NA
coords_df$lat[i] <- NA
}
}
save(coords_df, file="coords_breweries.RData")
} else {
load("coords_breweries.RData")
}
head(coords_df)
## step 3: plot breweries of Germany
pos <- filter(coords_df, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
germany <- worldmap[worldmap$name == 'Germany',]
ggplot() + geom_sf(data = germany) + theme_bw() + geom_point(aes(lon,lat), data = pos, size = .5, color = "red")
cities
?read_html
content <- read_html(url, encoding = "latin1")
content
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
cities
content <- read_html(url, encoding = "latin1")
anchors <- html_nodes(content, xpath = "//tr/td[3]")
cities <- html_text(anchors)
cities
library(tidyverse)
library(rvest)
<<<<<<< HEAD
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
phone
# diagnosis
str_extract("+test" , "\\+.+")
# diagnosis
str_extract("+test" , "\\+.+")
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
# solution
str_extract("+test" , "(?<=\\+).+")
str_extract_all("Hello, my name is Simon" , "[[a-z]., ]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^., ]") # equivalent
## load packages
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
library(RSelenium)
library(rJava)
rD <- rsDriver(browser = "chrome")
#rD <- rsDriver(browser = "firefox") # if chrome is causing some issues on your system, try (a) using the current beta, which you then have to install first, or (b) another browser, such as firefox
available.versions<-binman::list_versions("chromedriver")
latest.version = available.versions$win32[length(available.versions)]
latest.version
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
remDr$open()
remDr <- rD[["client"]]
remDr$open()
available.versions<-binman::list_versions("chromedriver")
latest.version = available.versions$win32[length(available.versions)]
latest.version
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
# set up connection
remDr <- rD[["client"]]
remDr$open()
startServer()
startServer()
library(rJava)
## load packages
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
library(RSelenium)
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
rm(rD)
gc()
remDr$close()
rm(rD)
gc()
rD <- rsDriver(browser = "chrome")
remDr$close()
rm(rD)
gc()
remDr$close()
rm(rD)
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.75", extraCapabilities = eCaps)
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
library(RSelenium)
rD <- rsDriver(verbose = FALSE,port=4444L)
remDr <- rD$client
remDr$close()
rD <- rsDriver(verbose = FALSE,port=4444L)
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
rD <- rsDriver(browser="chrom
rD <- rsDriver(browser="chrome")
rD <- rsDriver(browser="chrome")
remDr$open()
rD <- RSelenium::rsDriver(browser = "chrome",
chromever =
system2(command = "wmic",
args = 'datafile where name="C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe" get Version /value',
stdout = TRUE,
stderr = TRUE) %>%
stringr::str_extract(pattern = "(?<=Version=)\\d+\\.\\d+\\.\\d+\\.") %>%
magrittr::extract(!is.na(.)) %>%
stringr::str_replace_all(pattern = "\\.", replacement = "\\\\.") %>%
paste0("^",  .) %>%
stringr::str_subset(string = binman::list_versions(appname = "chromedriver") %>%
dplyr::last()) %>%
as.numeric_version() %>%
max() %>%
as.character())
driver <- rsDriver(browser=c("chrome"), chromever="86.0.4240.22", extraCapabilities = eCaps)
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="87.0.4280.20", extraCapabilities = eCaps)
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("chrome"), chromever="85.0.4183.87", extraCapabilities = eCaps)
?rsDriver
driver <- rsDriver(browser=c("firefox"), chromever="85.0.4183.87", extraCapabilities = eCaps)
rD <- rsDriver(browser="firefox")
remDr$open()
rD <- rsDriver(browser="firefox", version = "latest")
binman::list_versions("seleniumserver")
binman::list_versions("3.141.59")
rD <- rsDriver(browser="firefox", version = "3.141.59")
binman::list_versions("seleniumserver")
rD <- rsDriver(browser="firefox", version = "4.0.0-alpha-1")
remDr$open()
rD <- rsDriver()
remDr <- rD[["client"]]
remDr$navigate("http://www.google.com/ncr")
remDr$navigate("http://www.bbc.com")
rm(rD)
gc(rD)
binman::list_versions("seleniumserver")
binman::list_versions("chromeserver")
binman::list_versions("chromeserver")
binman::list_versions("chromedriver")
driver <- rsDriver(browser=c("firefox"), chromever="85.0.4183.87", extraCapabilities = eCaps)
driver <- rsDriver(browser=c("firefox"), chromever="85.0.4183.87")
driver <- rsDriver(
port = 4567L,
browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
version = "latest", browser=c("firefox"), chromever="85.0.4183.87")
driver <- rsDriver(
port = 4567L,
browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
version = "latest", chromever="85.0.4183.87")
available.versions<-binman::list_versions("chromedriver")
binman::list_versions("chromedriver")
driver <- rsDriver(
port = 4567L,
browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
version = "latest", chromever="87.0.4280.20")
remDr$open()
url <- "https://www.iea.org/policies"
remDr <- rD$client
remDr <- rD[["client"]]
rD <- rsDriver(browser = "chrome")
# set up connection
remDr <- rD[["client"]]
## load packages
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
#library(nominatim)
library(sf)
library(rnaturalearth)
library(RSelenium)
startServer()
library(rJava)
startServer()
?rsDriver
rD <- rsDriver(browser = "firefox")
rD <- rsDriver(browser = "firefox") # if chrome is causing some issues on your system, try (a) using the current beta, which you then have to install first, or (b) another browser, such as firefox
browseURL("www.hotmail.com",
browser = "C:/Program Files/Mozilla Firefox/firefox.exe")
browseURL("https://www.livescore.com/en/soccer/live/",
browser = "C:/Program Files/Mozilla Firefox/firefox.exe")
browseURL("https://www.livescore.com/en/soccer/live/", browser = getOption("firefox"))
browseURL("https://www.livescore.com/en/soccer/live/",
browser = "C:/Program Files/Mozilla Firefox/firefox.exe")
browseURL("https://www.livescore.com/en/soccer/live/"))
browseURL("https://www.livescore.com/en/soccer/live/")
rD <- rsDriver(browser = "chrome")
remDr <- rD[["client"]]
rD <- rsDriver(browser = "firefox") # if chrome is causing some issues on your system, try (a) using the current beta, which you then have to install first, or (b) another browser, such as firefox
remDr <- rD[["client"]]
binman::list_versions("chromedriver")
driver <- rsDriver(
port = 4567L,
browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
version = "latest", chromever="87.0.4280.20")
driver <- rsDriver(
port = 4567L,
browser = "chrome",
version = "latest", chromever="87.0.4280.20")
binman::list_versions("chromedriver")
driver <- rsDriver(
port = 4567L,
browser = "chrome",
version = "latest", chromever="86.0.4240.22")
remDr$navigate(url
remDr$navigate(url)
remDr <- rD$client
remDr <- rD[["client"]]
=======
library(pdftools)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
## step 1: inspect page
url <- "http://ajps.org/list-of-reviewers/"
browseURL(url)
## step 3: import pdf
rev_raw <- pdftools::pdf_text("ajps-reviewers/reviewers2015.pdf")
class(rev_raw)
rev_raw[1]
## step 4: tidy data
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
rev_all
surname <- str_extract(rev_all, "[[:alpha:]-]+")
prename <- str_extract(rev_all, " [.[:alpha:]-]+")
## step 4: tidy data
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
surname <- str_extract(rev_all, "[[:alpha:]-]+")
prename <- str_extract(rev_all, " [.[:alpha:]-]+")
rev_df <- data.frame(raw = rev_all, surname = surname, prename = prename, stringsAsFactors = F)
head(rev_df)
rev_df$institution <- NA
rev_df$institution <- NA
for(i in 1:nrow(rev_df)) {
rev_df$institution[i] <- rev_df$raw[i] %>% str_replace(rev_df$surname[i], "") %>% str_replace(rev_df$prename[i], "") %>% str_trim()
}
rev_df <- rev_df[-c(1,2),]
rev_df <- rev_df[!is.na(rev_df$surname),]
head(rev_df)
nrow(rev_df)
?pdf_text
?data.frame
default.stringsAsFactors()
sessionInfo()
?httr
url <- "https://en.wikipedia.org/wiki/List_of_female_scientists_in_the_20th_century"
browseURL(url)
url <- "https://en.wikipedia.org/wiki/List_of_female_scientists_in_the_20th_century"
url_parsed <- read_html(url)
xpath <- "//h2[./span[@id='Anthropology']]/following-sibling::ul[1]/li"
html_nodes(url_parsed, xpath = xpath) %>% html_text()
# load RSelenium
library(tidyverse)
library(rvest)
library(RSelenium)
# initiate Selenium driver
rD <- rsDriver(browser = "chrome")
remDr <- rD[["client"]]
# start browser, navigate to page
url <- "https://www.imdb.com/search/title"
remDr$navigate(url)
# enter keyword in title field
xpath <- '//*[@id="main"]/div[1]/div[2]/input'
titleElem <- remDr$findElement(using = 'xpath', value = xpath)
titleElem$sendKeysToElement(list("data")) # enter key word
# select requested title data
xpath <- '//*[@id="main"]/div[8]/div[2]/select/option[7]' # plot
titledatElem1 <- remDr$findElement(using = 'xpath', value = xpath)
titledatElem1$clickElement() # click on list element
xpath <- '//*[@id="main"]/div[8]/div[2]/select/option[10]' # technical info
titledatElem2 <- remDr$findElement(using = 'xpath', value = xpath)
titledatElem2$clickElement() # click on list element
# scroll to end of page (just for fun)
webElem <- remDr$findElement("css", "body")
webElem$sendKeysToElement(list(key = "end"))
# click on search button
xpath <- '//*[@id="main"]/p[3]/button'
searchElem <- remDr$findElement(using = 'xpath', value = xpath)
searchElem$clickElement() # click on button
# store index page
output <- remDr$getPageSource(header = TRUE)
dir.create("data")
output[[1]]
write(output[[1]], file = "data/imdb-data-movies.html")
# close connection
remDr$closeServer()
# parse html
content <- read_html("data/imdb-data-movies.html")
titles <- html_nodes(content, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "lister-item-header", " " ))]//a') %>% html_text
head(titles)
foo <- jsonlite::fromJSON("https://projects.fivethirtyeight.com/2020-election-forecast/house_seats.json")
foo
>>>>>>> 46f5126cd0b1f469af3c6c745d3505a0798f6d90
